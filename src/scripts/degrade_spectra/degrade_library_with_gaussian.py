#!../../../../virtualenv/bin/python2.7
# -*- coding: utf-8 -*-

# NB: The shebang line above assumes you've installed a python virtual environment alongside your working copy of the
# <4most-4gp-scripts> git repository. It also only works if you invoke this python script from the directory where it
# is located. If these two assumptions are incorrect (e.g. you're using Conda), you can still use this script by typing
# <python degrade_library_with_gaussian.py>, but <./degrade_library_with_gaussian.py> will not work.

"""
Take a library of spectra, perhaps generated by Turbospectrum, add Gaussian noise to them, and resample them onto a
raster of wavelengths which matches what the 4FS ETC generates. We create a pair of new spectrum libraries, containing
mock observations of the input spectra, for 4MOST LRS and HRS.
"""

import argparse
import os
from os import path as os_path
import hashlib
import time
import re
import logging
import numpy as np

from fourgp_speclib import SpectrumLibrarySqlite
from fourgp_degrade import GaussianNoise

logging.basicConfig(level=logging.INFO, format='[%(asctime)s] %(levelname)s:%(filename)s:%(message)s',
                    datefmt='%d/%m/%Y %H:%M:%S')
logger = logging.getLogger(__name__)

# Read input parameters
our_path = os_path.split(os_path.abspath(__file__))[0]
root_path = os_path.join(our_path, "../..")
pid = os.getpid()
parser = argparse.ArgumentParser(description=__doc__.strip())
parser.add_argument('--input-library',
                    required=False,
                    default="turbospec_apokasc_training_set",
                    dest="input_library",
                    help="The name of the spectrum library we are to read input spectra from. A subset of the stars "
                         "in the input library may optionally be selected by suffixing its name with a comma-separated "
                         "list of constraints in [] brackets. Use the syntax my_library[Teff=3000] to demand equality, "
                         "or [0<[Fe/H]<0.2] to specify a range. We do not currently support other operators like "
                         "[Teff>5000], but such ranges are easy to recast is a range, e.g. [5000<Teff<9999].")
parser.add_argument('--output-library-lrs',
                    required=False,
                    default="convolved_apokasc_training_set_lrs",
                    dest="output_library_lrs",
                    help="The name of the spectrum library we are to feed mock LRS observations into.")
parser.add_argument('--output-library-hrs',
                    required=False,
                    default="convolved_apokasc_training_set_hrs",
                    dest="output_library_hrs",
                    help="The name of the spectrum library we are to feed mock HRS observations into.")
parser.add_argument('--workspace', dest='workspace', default="",
                    help="Directory where we expect to find spectrum libraries.")
parser.add_argument('--snr-definition',
                    action="append",
                    dest="snr_definitions",
                    help="Specify a way of defining SNR, in the form 'name,minimum,maximum', meaning we calculate the "
                         "median SNR per pixel between minimum and maximum wavelengths in Angstrom.")
parser.add_argument('--snr-list',
                    required=False,
                    default="10,12,14,16,18,20,23,26,30,35,40,45,50,80,100,130,180,250",
                    dest="snr_list",
                    help="Specify a comma-separated list of the SNRs that we are to degrade spectra to.")
parser.add_argument('--snr-definitions-lrs',
                    required=False,
                    default="",
                    dest="snr_definitions_lrs",
                    help="Specify the SNR definition to use for LRS. For example, 'GalDiskHR_536NM' to use the S4 "
                         "green definition of SNR. You can even specify three comma-separated definitions, e.g. "
                         "'GalDiskHR_536NM,GalDiskHR_536NM,GalDiskHR_536NM' to use different SNR metrics for the "
                         "RGB arms within 4MOST LRS, though this is a pretty weird thing to want to do.")
parser.add_argument('--snr-definitions-hrs',
                    required=False,
                    default="",
                    dest="snr_definitions_hrs",
                    help="Specify the SNR definition to use for HRS. For example, 'GalDiskHR_536NM' to use the S4 "
                         "green definition of SNR. You can even specify three comma-separated definitions, e.g. "
                         "'GalDiskHR_536NM,GalDiskHR_536NM,GalDiskHR_536NM' to use different SNR metrics for the "
                         "RGB arms within 4MOST HRS, though this is a pretty weird thing to want to do.")
parser.add_argument('--create',
                    action='store_true',
                    dest="create",
                    help="Create a clean spectrum library to feed output spectra into. Will throw an error if "
                         "a spectrum library already exists with the same name.")
parser.add_argument('--no-create',
                    action='store_false',
                    dest="create",
                    help="Do not create a clean spectrum library to feed output spectra into.")
parser.set_defaults(create=True)
parser.add_argument('--log-file',
                    required=False,
                    default="/tmp/gaussian_convolution_{}.log".format(pid),
                    dest="log_to",
                    help="Specify a log file where we log our progress.")
args = parser.parse_args()

logger.info("Adding Gaussian noise to spectra from <{}>, going into <{}> <{}>".format(args.input_library,
                                                                                      args.output_library_lrs,
                                                                                      args.output_library_hrs))

# Set path to workspace where we create libraries of spectra
workspace = args.workspace if args.workspace else os_path.join(our_path, "../../../workspace")
os.system("mkdir -p {}".format(workspace))

# Open input SpectrumLibrary, and search for flux normalised spectra meeting our filtering constraints
spectra = SpectrumLibrarySqlite.open_and_search(library_spec=args.input_library,
                                                workspace=workspace,
                                                extra_constraints={"continuum_normalised": 0}
                                                )

# Get a list of the spectrum IDs which we were returned
input_library, input_spectra_ids, input_spectra_constraints = [spectra[i] for i in ("library", "items", "constraints")]

# Create new SpectrumLibrary
output_libraries = {}

for mode in ({"name": "lrs", "library": args.output_library_lrs},
             {"name": "hrs", "library": args.output_library_hrs}):
    # Create spectrum library
    library_name = re.sub("/", "_", mode['library'])
    library_path = os_path.join(workspace, library_name)
    output_libraries[mode['name']] = SpectrumLibrarySqlite(path=library_path, create=args.create)

# Parse any definitions of SNR we were supplied on the command line
if (args.snr_definitions is None) or (len(args.snr_definitions) < 1):
    snr_definitions = None
else:
    snr_definitions = []
    for snr_definition in args.snr_definitions:
        words = snr_definition.split(",")
        snr_definitions.append([words[0], float(words[1]), float(words[2])])

# Look up what definition of SNR is user specified we should use for 4MOST LRS
if len(args.snr_definitions_lrs) < 1:
    # Case 1: None was specified, so we use default
    snr_definitions_lrs = None
else:
    snr_definitions_lrs = args.snr_definitions_lrs.split(",")
    # Case 2: A single definition was supplied which we use for all three arms
    if len(snr_definitions_lrs) == 1:
        snr_definitions_lrs *= 3
    # Case 3: Three definitions were supplied, one for each arm
    assert len(snr_definitions_lrs) == 3

# Look up what definition of SNR is user specified we should use for 4MOST HRS
if len(args.snr_definitions_hrs) < 1:
    # Case 1: None was specified, so we use default
    snr_definitions_hrs = None
else:
    snr_definitions_hrs = args.snr_definitions_hrs.split(",")
    # Case 2: A single definition was supplied which we use for all three arms
    if len(snr_definitions_hrs) == 1:
        snr_definitions_hrs *= 3
    # Case 3: Three definitions were supplied, one for each arm
    assert len(snr_definitions_hrs) == 3

# Parse the list of SNRs that the user specified on the command line
snr_list = [float(item.strip()) for item in args.snr_list.split(",")]

# Read wavelength rasters we're going to use for mock LRS and HRS observations
raster_hrs = np.loadtxt(os_path.join(our_path, "raster_hrs.txt")).transpose()[0]
raster_lrs = np.loadtxt(os_path.join(our_path, "raster_lrs.txt")).transpose()[0]

# Instantiate Gaussian noise model
modes = {
    "hrs": GaussianNoise(
        wavelength_raster=raster_hrs,
        snr_definitions=snr_definitions,
        use_snr_definitions=snr_definitions_hrs,
        snr_list=snr_list
    ),
    "lrs": GaussianNoise(
        wavelength_raster=raster_lrs,
        snr_definitions=snr_definitions,
        use_snr_definitions=snr_definitions_lrs,
        snr_list=snr_list
    )
}

# Start making a log file
with open(args.log_to, "w") as result_log:
    # Loop over spectra to process
    for input_spectrum_id in input_spectra_ids:
        logger.info("Working on <{}>".format(input_spectrum_id['filename']))
        # Open Spectrum data from disk
        input_spectrum_array = input_library.open(ids=input_spectrum_id['specId'])

        # Turn SpectrumArray object into a Spectrum object
        input_spectrum = input_spectrum_array.extract_item(0)

        # Look up the unique ID of the star we've just loaded
        # Newer spectrum libraries have a uid field which is guaranteed unique; for older spectrum libraries use
        # Starname instead.

        # Work out which field we're using (uid or Starname)
        spectrum_matching_field = 'uid' if 'uid' in input_spectrum.metadata else 'Starname'

        # Look up the unique ID of this object
        object_name = input_spectrum.metadata[spectrum_matching_field]

        # Write log message
        result_log.write("\n[{}] {}... ".format(time.asctime(), object_name))
        result_log.flush()

        # Search for the continuum-normalised version of this same object (which will share the same uid / name)
        search_criteria = input_spectra_constraints.copy()
        search_criteria[spectrum_matching_field] = object_name
        search_criteria['continuum_normalised'] = 1
        continuum_normalised_spectrum_id = input_library.search(**search_criteria)

        # Check that continuum-normalised spectrum exists and is unique
        assert len(continuum_normalised_spectrum_id) == 1, "Could not find continuum-normalised spectrum."

        # Load the continuum-normalised version
        input_spectrum_continuum_normalised_arr = input_library.open(
            ids=continuum_normalised_spectrum_id[0]['specId']
        )

        # Turn the SpectrumArray we got back into a single Spectrum
        input_spectrum_continuum_normalised = input_spectrum_continuum_normalised_arr.extract_item(0)

        # Process spectra through Gaussian noise model
        degraded_spectra = {}
        for mode_name, noise_model in modes.iteritems():
            degraded_spectra[mode_name] = noise_model.process_spectra(
                spectra_list=((input_spectrum, input_spectrum_continuum_normalised),)
            )

        # Import degraded spectra into output spectrum library

        # Loop over LRS and HRS
        for mode in degraded_spectra:
            # Loop over the spectra we simulated (there was only one!)
            for index in range(len(degraded_spectra[mode])):
                # Loop over the various SNRs we simulated
                for snr in degraded_spectra[mode][index]:
                    # Create a unique ID for this mock observation
                    unique_id = hashlib.md5(os.urandom(32).encode("hex")).hexdigest()[:16]
                    # Import the flux- and continuum-normalised spectra separately, but give them the same ID
                    for spectrum_version in degraded_spectra[mode][index][snr]:
                        output_libraries[mode].insert(spectra=spectrum_version,
                                                      filenames=input_spectrum_id['filename'],
                                                      metadata_list={"uid": unique_id})

# Clean up noise models
for mode in modes.itervalues():
    mode.close()
